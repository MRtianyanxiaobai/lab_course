{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 聚类学习算法对比评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非监督学习（英语：Unsupervised learning）是机器学习中十分重要的一个分支。在前几个实验我们学习了将 K-Means 和 GMM 用于聚类。本次实验，将带你了解更多聚类算法，并完成聚类算法对照实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 常用聚类算法的概念\n",
    "- 常用聚类算法的实现\n",
    "- 常用聚类算法的对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更多聚类算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini Batch K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.MiniBatchKMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html#sklearn.cluster.MiniBatchKMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini Batch K-Means 整体上和 K-Means 很相似，它是 K-Means 的一个变种形式。与 K-Means 不同的地方在于，其每次从全部数据集中抽样小数据集进行迭代。Mini Batch K-Means 算法在不对聚类效果造成较大影响的前提下，大大缩短了计算时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affinity Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.AffinityPropagation](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinity Propagation 又被称为亲和传播聚类。Affinity Propagation 是基于数据点进行消息传递的理念设计的。与 K-Means 等聚类算法不同的地方在于，亲和传播聚类不需要提前确定聚类的数量，即 K 值，但是运行效率较低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.MeanShift](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html#sklearn.cluster.MeanShift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeanShift 又被称为均值漂移聚类。Mean Shift 聚类的目的是找出最密集的区域， 同样也是一个迭代过程。在聚类过程中，首先算出初始中心点的偏移均值，将该点移动到此偏移均值，然后以此为新的起始点，继续移动，直到满足最终的条件。Mean Shift 也引入了核函数，用于改善聚类效果。除此之外，Mean Shift 在图像分割，视频跟踪等领域也有较好的应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectral Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.SpectralClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering 又被称为谱聚类。谱聚类同样也是一种比较常见的聚类方法，它是从图论中演化而来的。谱聚类一开始将特征空间中的点用边连接起来。其中，两个点距离越远，那么边所对应的权值越低。同样，距离越近，那么边对应的权值越高。最后，通过对所有特征点组成的网络进行切分，让切分后的子图互相连接的边权重之和尽可能的低，而各子图内部边组成的权值和尽可能高，从而达到聚类的效果。谱聚类的好处是能够识别任意形状的样本空间，并且可以得到全局最优解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.AgglomerativeClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative Clustering 又被称为层次聚类。层次聚类算法是将所有的样本点自下而上合并组成一棵树的过程，它不再产生单一聚类，而是产生一个聚类层次。层次聚类通过计算各样本数据之间的距离来确定它们的相似性关系，一般情况下，距离越小就代表相似度越高。最后，将相似度越高的样本归为一类，依次迭代，直到生成一棵树。由于层次聚类涉及到循环计算，所以时间复杂度比较高，运行速度较慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Birch 聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.Birch](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html#sklearn.cluster.Birch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birch 是英文 Balanced Iterative Reducing and Clustering Using Hierarchies 的简称，它的中文译名为「基于层次方法的平衡迭代规约和聚类」，名字实在太长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birch 引入了聚类特征树（CF 树），先通过其他的聚类方法将其聚类成小的簇，然后再在簇间采用 CF 树对簇聚类。Birch 的优点是，只需要单次扫描数据集即可完成聚类，运行速度较快，特别适合大数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现方法：[sklearn.cluster.DBSCAN](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN 是英文 Density-based spatial clustering of applications with noise 的简称，它的中文译名为「基于空间密度与噪声应用的聚类方法」，名字同样很长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN 基于密度概念，要求聚类空间中的一定区域内所包含的样本数目不小于某一给定阈值。该算法运行速度快，且能够有效处理特征空间中存在的噪声点。但是对于密度分布不均匀的样本集合，DBSCAN 的表现较差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聚类算法对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我们从 `sklearn.cluster` 模块中，导入各聚类估计器。如 K-Means 等估计器需要提前确定类别数量，也就是 K 值。判断的方法很简单，如果聚类方法中包含 `n_clusters=` 参数，即代表需要提前指定。这里我们统一确定 `K=3`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster  # 导入聚类模块\n",
    "\n",
    "# 对聚类方法依次命名\n",
    "cluster_names = ['KMeans', 'MiniBatchKMeans', 'AffinityPropagation', 'MeanShift',\n",
    "                 'SpectralClustering', 'AgglomerativeClustering', 'Birch', 'DBSCAN']\n",
    "\n",
    "# 确定聚类方法相应参数\n",
    "cluster_estimators = [\n",
    "    cluster.KMeans(n_clusters=3),\n",
    "    cluster.MiniBatchKMeans(n_clusters=3),\n",
    "    cluster.AffinityPropagation(),\n",
    "    cluster.MeanShift(),\n",
    "    cluster.SpectralClustering(n_clusters=3),\n",
    "    cluster.AgglomerativeClustering(n_clusters=3),\n",
    "    cluster.Birch(n_clusters=3),\n",
    "    cluster.DBSCAN()\n",
    "]\n",
    "print(\"定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们对上面提到的 8 种常见的聚类算法做一个对比。这里选择了一个空间分布由三个团状图案组成的示例数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # 导入数据处理模块\n",
    "from matplotlib import pyplot as plt  # 导入绘图模块\n",
    "%matplotlib inline\n",
    "\n",
    "# 读取数据集 csv 文件\n",
    "data = pd.read_csv(\n",
    "    \"https://labfile.oss.aliyuncs.com/courses/880/data_blobs.csv\", header=0)\n",
    "X = data[['x', 'y']]\n",
    "plt.scatter(data['x'], data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们分别应用 8 种聚类方法对数据进行聚类，并将最终的聚类结果绘制出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # 导入数值计算模块\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "plot_num = 1  # 为绘制子图准备\n",
    "plt.figure(figsize=(20, 10))\n",
    "# 不同的聚类方法依次运行\n",
    "for name, algorithm in tqdm_notebook(zip(cluster_names, cluster_estimators)):\n",
    "    algorithm.fit(X)  # 聚类\n",
    "    # 判断方法中是否有 labels_ 参数，并执行不同的命令\n",
    "    if hasattr(algorithm, 'labels_'):\n",
    "        algorithm.labels_.astype(np.int)\n",
    "    else:\n",
    "        algorithm.predict(X)\n",
    "    # 绘制子图\n",
    "    plt.subplot(2, len(cluster_estimators) / 2, plot_num)\n",
    "    plt.scatter(data['x'], data['y'], c=algorithm.labels_)\n",
    "    # 判断方法中是否有 cluster_centers_ 参数，并执行不同的命令\n",
    "    if hasattr(algorithm, 'cluster_centers_'):\n",
    "        centers = algorithm.cluster_centers_\n",
    "        plt.scatter(centers[:, 0], centers[:, 1], marker=\"p\", edgecolors=\"red\")\n",
    "    # 绘制图标题\n",
    "    plt.title(name)\n",
    "    plot_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在我们指定 `n_clusters=3` 的方法中，除了 SpectralClustering 出现了三个样本点漂移，其他几种方法的结果几乎是一致的。除此之外，在没有指定 `n_clusters` 的聚类估计器中，Mean Shift 对于此数据集的适应性较好，而亲和传播聚类方法在默认参数下表现最差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类方法这么多，在实际运用中我们该怎样选择呢？其实，scikit-learn 提供了一张选择判断图供大家参考。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='700px' src=\"https://doc.shiyanlou.com/document-uid214893labid3189timestamp1500001986202.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验，了解了除 K-Means、GMM 之外的其他几种聚类方法。并通过对比实验，测试了不同方法对于同一数据集的聚类效果。由于测试集相对简单，所以这里的目的并不是对比各类方法的好坏。每一类方法都有自己的优点和缺点，它们针对不同测试集的适应性也会不一样，不能单纯地用好或不好来以偏概全。实验的目的是了解和学会简单使用这些方法，如果要想进一步将机器学习方法用于实践，深入了解背后的数学理论才是关键。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><div style=\"color: #999; font-size: 12px;\"><i class=\"fa fa-copyright\" aria-hidden=\"true\"> 本课程内容版权归实验楼所有，禁止转载、下载及非法传播。</i></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
