{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 监督学习算法对比评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习（英语：Supervised learning）是机器学习中最为常见、应用最为广泛的分支之一。在前面的几个实验中我们了解了几个监督学习算法，本次实验将带你大概了解其他监督学习算法，并用 scikit-learn 来构建预测几乎所有的监督学习模型，进行算法间的对比评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K 近邻算法\n",
    "- 其他常用监督学习方法\n",
    "- 常用算法对比评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了前面三节介绍过的线性模型、支持向量机以及随机森林，还有很多监督学习方法都非常流行。例如：K 近邻、朴素贝叶斯等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K 近邻"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K 近邻是一种十分常用的监督学习算法。简单来讲，K 近邻就是假设一个给定的数据集，且数据的类别已经确定。这些数据的特征所构成的特征向量可以映射到对应的特征空间中。现在，假设一个输入实例，我们可以计算该输入和其他数据点之间的距离，再通过多数表决的方式，来确定新输入实例的类别，最后完成分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，K 近邻中的「近邻」代表原有特征空间中与新输入实例距离最近的那些样本。而 K 代表距离最近的 K 个样本。所以，对于 K 近邻而言。K 值的大小和距离的度量方式（欧式距离或者曼哈顿距离）是其构成的两个关键因素。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图片描述](https://doc.shiyanlou.com/courses/uid214893-20190523-1558588451060)\n",
    "<div style=\"color: #888; font-size: 10px; text-align: right;\"><a href=\"https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\"><i class=\"fa fa-copyright\" aria-hidden=\"true\"> 来源</i></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上图所示，原数据集由红、绿两类组成。现在，我们新输入一个橙色实例，图中表示了样本对应在特征空间的位置。现在，我们确定 K = 3，然后可以圈定出距离橙色实例最近的 3 个样本点。其中，红色样本为 1 个，绿色 2 个。根据多数表决的规则，最终确定新输入的橙色样本数据被判定为 B 类别。而当我们指定 K = 7 时，红色样本 4 个，绿色样本 3 个，则橙色样本被判定为 A 类别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "监督学习包含的方法众多，在此就不再一一介绍。下面我们直接上手，看一看 scikit-learn 中一些常用监督学习方法的分类效果如何。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常见监督学习算法对比评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们通过同一个示例数据集来对常见的监督学习算法分类性能做一个比较。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更方便可视化，这里选用了一个随机生成的二分类数据集。总共包含 300 条数据，类别为 0 和 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，你可以通过 Pandas 读取数据集并预览这些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # 加载 pandas 模块\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 读取 csv 文件, 并将第一行设为表头\n",
    "data = pd.read_csv(\n",
    "    \"https://labfile.oss.aliyuncs.com/courses/866/class_data.csv\", header=0)\n",
    "data.head()  # 输出数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用 Matplotlib 来可视化这些数据。只需要 3 行代码，就可以画出数据集的散点图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt  # 加载绘图模块\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(data[\"X\"], data['Y'], c=data['CLASS'])  # 绘制散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面，我们用 `c=data['CLASS']` 参数来控制散点的颜色。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，加载本次实验需要的模块，以及 scikit-learn 中常见的估计器。你也可以通过 [<i class=\"fa fa-external-link-square\" aria-hidden=\"true\"> 官方文档</i>](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) 对应的页面来查看这些分类方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集成方法分类器\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 高斯过程分类器\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# 广义线性分类器\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# K近邻分类器\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 朴素贝叶斯分类器\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# 神经网络分类器\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# 决策树分类器\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "# 支持向量机分类器\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，建立预测模型，采用默认参数即可。由于方法较多，所有这里就不再依次单独定义模型，而是用列表形式管理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "models = [\n",
    "    AdaBoostClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianProcessClassifier(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    RidgeClassifier(),\n",
    "    SGDClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    ExtraTreeClassifier(),\n",
    "    SVC(),\n",
    "    LinearSVC()\n",
    "]\n",
    "\n",
    "# 依次为模型命名\n",
    "classifier_Names = ['AdaBoost', 'Bagging', 'ExtraTrees',\n",
    "                    'GradientBoosting', 'RandomForest', 'GaussianProcess',\n",
    "                    'PassiveAggressive', 'Ridge', 'SGD',\n",
    "                    'KNeighbors', 'GaussianNB', 'MLP',\n",
    "                    'DecisionTree', 'ExtraTree', 'SVC', 'LinearSVC']\n",
    "print(\"定义完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，划分数据集，70% 用于训练，另外 30% 用于测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # 导入数据集切分模块\n",
    "\n",
    "feature = data[['X', 'Y']]  # 指定特征变量\n",
    "target = data['CLASS']  # 指定标签变量\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    feature, target, test_size=.3)  # 切分数据集\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备好数据之后，就可以开始模型训练和测试了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score  # 导入准确度评估模块\n",
    "\n",
    "# 遍历所有模型\n",
    "for name, model in zip(classifier_Names, models):\n",
    "    model.fit(X_train, y_train)  # 训练模型\n",
    "    pre_labels = model.predict(X_test)  # 模型预测\n",
    "    score = accuracy_score(y_test, pre_labels)  # 计算预测准确度\n",
    "    print('%s: %.2f' % (name, score))  # 输出模型准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，这 16 个分类器最终的准确度均在 80% ~ 90% 之间，差距不是很大。对于这种现象，主要有两个原因。首先，本次使用的是一个非常规范整洁的线性分类数据集。其次，所有的分类器均采用了默认参数，而 scikit-learn 提供的默认参数一般已经较优。但这个准确度并不能断定哪种分类器性能更优，具体的分类效果表现还取决于参数的选择，比如在第三个关于支持向量机的实验中，实验最后我们提到将 gamma 系数调整一下，预测结果会大大得提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们通过可视化的方法将每一个模型在分类时的决策边界展示出来，这样能更加直观的感受到机器学习模型在执行分类预测时发生的变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续编写代码。书写代码时，一定要注意格式缩进，以免运行时报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap  # 加载色彩模块\n",
    "import numpy as np  # 导入数值计算模块\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# 绘制数据集\n",
    "i = 1  # 为绘制子图设置的初始编号参数\n",
    "cm = plt.cm.Reds  # 为绘制等高线选择的样式\n",
    "cm_color = ListedColormap(['red', 'yellow'])  # 为绘制训练集和测试集选择的样式\n",
    "\n",
    "# 栅格化\n",
    "x_min, x_max = data['X'].min() - .5, data['X'].max() + .5\n",
    "y_min, y_max = data['Y'].min() - .5, data['Y'].max() + .5\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, .1),\n",
    "                     np.arange(y_min, y_max, .1))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "for name, model in tqdm_notebook(zip(classifier_Names, models)):\n",
    "    ax = plt.subplot(4, 4, i)  # 绘制 4x4 子图\n",
    "\n",
    "    model.fit(X_train, y_train)  # 模型训练\n",
    "    pre_labels = model.predict(X_test)  # 模型测试\n",
    "    score = accuracy_score(y_test, pre_labels)  # 模型准确度\n",
    "\n",
    "    # 根据类的不同选择决策边界计算方法\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "        Z = model.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    else:\n",
    "        Z = model.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "    # 绘制决策边界等高线\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, cmap=cm, alpha=.6)\n",
    "\n",
    "    # 绘制训练集和测试集\n",
    "    ax.scatter(X_train['X'], X_train['Y'], c=y_train, cmap=cm_color)\n",
    "    ax.scatter(X_test['X'], X_test['Y'], c=y_test,\n",
    "               cmap=cm_color, edgecolors='black')\n",
    "\n",
    "    # 图形样式设定\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title('%s | %.2f' % (name, score))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图将决策边界绘制了出来，并用等高线图显示。其中，颜色越深表示偏向于黄色散点分类的概率越高，而颜色越浅，则表示偏向红色散点的概率越高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了进一步探索各分类器对于不同特征分布的数据集的适用情况。接下来，我们将原有数据集做一些变换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前几节的课程中，我们知道了 `make_circles` 可以生成环形形状的数据，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# 生成 200 个包含噪声的环状样本\n",
    "circles = datasets.make_circles(n_samples=200, noise=.1)\n",
    "plt.scatter(circles[0][:, 0], circles[0][:, 1], c=circles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们还用 `make_moons` 来生成两个交织间隔圆环样式的数据集，即月牙型的数据。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成 300 个包含噪声的月牙状样本\n",
    "moons = datasets.make_moons(n_samples=300, noise=.2, random_state=1)\n",
    "plt.scatter(moons[0][:, 0], moons[0][:, 1], c=moons[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这两组数据都是无法进行线性分类，所以如果是非线性分类器，其结果应该会好很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对环状样本进行分割测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    circles[0], circles[1], test_size=0.3)\n",
    "\n",
    "print(\"环状样本预测：\")\n",
    "for name, model in zip(classifier_Names, models):\n",
    "    model.fit(X_train, y_train)  # 训练模型\n",
    "    pre_labels = model.predict(X_test)  # 模型预测\n",
    "    score = accuracy_score(y_test, pre_labels)  # 计算预测准确度\n",
    "    print('%s: %.2f' % (name, score))  # 输出模型准确度\n",
    "\n",
    "print(\"******************************\")\n",
    "print()\n",
    "\n",
    "print(\"月牙状样本测试：\")\n",
    "# 对月牙状样本进行分割测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    moons[0], moons[1], test_size=0.3)\n",
    "\n",
    "for name, model in zip(classifier_Names, models):\n",
    "    model.fit(X_train, y_train)  # 训练模型\n",
    "    pre_labels = model.predict(X_test)  # 模型预测\n",
    "    score = accuracy_score(y_test, pre_labels)  # 计算预测准确度\n",
    "    print('%s: %.2f' % (name, score))  # 输出模型准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上，我们用线性数据和非线性数据进行了分类器的算法测试评估，你还可以尝试通过 `sklearn.datasets.make_multilabel_classification` 方法来生成一个多类别的数据集，并通过常见的非线性分类器完成分类，查看其分类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验对比了 scikit-learn 中常见的监督学习方法，我们可以看出不同方法之间差别。另外，对于不同空间分布的数据集，模型的适用性也不一样。大多数非线性分类模型的表现和适用性都较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><div style=\"color: #999; font-size: 12px;\"><i class=\"fa fa-copyright\" aria-hidden=\"true\"> 本课程内容版权归实验楼所有，禁止转载、下载及非法传播。</i></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
