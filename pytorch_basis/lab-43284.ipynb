{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于迁移学习的蚁蜂分类模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练深度学习模型时，有时我们没有海量的训练样本，只有少数的训练样本(比如几百个图片)，这显然对于深度学习远远不够。这时候，我们可以使用别人预训练好的网络模型权重，在此基础上进行训练，这就是迁移学习(Transfer Learning)。本实验将利用迁移学习的概念，训练一个蜜蜂和蚂蚁的分类模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据的预处理\n",
    "- 迁移学习\n",
    "- 预训练模型\n",
    "- 模型的训练与测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  数据的预处理 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在建立模型之前，让我们还是先从实验楼中下载所需要的数据集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://labfile.oss.aliyuncs.com/courses/2534/hymenoptera_data.zip\n",
    "!unzip hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们查看一下 该数据集的结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls  hymenoptera_data\n",
    "!ls  hymenoptera_data/train  \n",
    "!ls  hymenoptera_data/val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到该数据集已经将训练数据和测试数据分开，且它们里面都存在着两个类别的数据：蜜蜂图像和蚂蚁图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体图像如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://doc.shiyanlou.com/courses/2534/1166617/18f1acac22d63bbb8d1c141de3c965fe-0/wm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的目的就是建立一个良好的模型，使其能够判断任意一张图像是蜜蜂还是蚂蚁。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在加载数据之前，让我们还是先来定义数据预处理的操作集合。我们可以使用旋转、剪切等操作，扩大数据集合的多样性。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "# 用于存在标准化，因此这里定义了高斯分布所需要的两个参数：均值和标准差\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "data_transforms = {\n",
    "\n",
    "    'train': transforms.Compose([\n",
    "        # 加入旋转等数据增强技术，加大模型训练的难度，提高模型的稳健性\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    # 测试集输入时，无需加入旋转等操作\n",
    "    'val': transforms.Compose([\n",
    "        # resize 操作的目的是将任意大小的图片转为模型规定的输入大小\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}\n",
    "data_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据的加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，就让我们加载数据集合，并且将其制作成 PyTorch 能够识别的数据加载器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'hymenoptera_data'\n",
    "# 将数据集封装到 PyTorch 中数据加载器中\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                              shuffle=True, num_workers=0)\n",
    "               for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "# 判断当前环境\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们还是利用定义好的数据加载器随机展示几张数据集中的图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def imshow(inp, title):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 获得训练数据中的一个批次的数据\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# 将图片拼成一个网格\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "# 展示图像\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的建立"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 迁移学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "迁移学习的核心思想其实就是将一个问题的训练模型应用到其他模型之中。当然这种转移并不是完完全全的复制，在迁移的过程中我们也需要调节模型的参数。简单的说，就是一种迁移学习举一反三的学习能力。比如我们学会其自行车后，学习骑摩托车就会很简单。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "举个例子，如果我们这里已经存在一个模型，该模型是用于猫狗分类的一个模型，模型准确率能够达到 80%。而此时我们需要解决的问题是蚂蚁和蜜蜂的分类问题，我们可以重新建立一个模型进行训练。我们也可以将猫狗分类模型作为蜂蚁分类模型的初始模型，进行训练。这个将一个问题的已训练模型加载到另一个问题之中，作为初始模型的过程叫做迁移学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传统的模型训练就是建立一个神经网络结构，给该网络结构的参数进行随机取值。然后将数据集放入模型中进行训练，在训练过程中优化模型参数的过程。如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"600px\" src=\"https://doc.shiyanlou.com/courses/2534/1166617/f3a236c6897175a6f914cb9008b5ab0e-0/wm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样的网络结构下，迁移学习就是在模型训练之前，先给该网络结构赋予初值，然后再进行模型的训练，优化模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么这些初值是哪里来的呢？这些初值可以来自与本任务无关的其他任务的训练模型之中。如下图，蜂蚁分类模型的初始模型其实就是猫狗分类的已训练模型（这种已经训练好的模型，也被称之为预训练模型，即提前训练的模型。）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"400px\" src=\"https://doc.shiyanlou.com/courses/2534/1166617/aba974e4122f8e0c1e8c1055c7caabc8-0/wm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上所示，如果在之前的学习中，我们已经训练了一个猫狗分类的模型。然后今天需要训练一个蚂蚁和蜜蜂的分类模型，由于都是二分类问题，我们就可以借用猫狗分类的神经网络结构以及它的模型参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，如果直接用猫狗分类器来分类蚂蚁和蜜蜂的话，那么准确率一样会很低。因此，我们还是需要进行模型的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，迁移学习的训练和传统模型的训练的唯一不同就是，在模型初始化时的参数的取值方式不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的结论可以看出，无论我们是否引入预训练模型，仿佛我们都需要进行模型的训练，那么我们引入预训练模型有什么好处呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中的缘由非常复杂，这里直接告诉你一个结论：我们引入预训练模型，可以大大地提高模型的训练速度。即采用预训练模型中的参数作为训练的开始，比随机初始化模型参数的收敛速度快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 预训练模型的加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 已经将一些经典的网络结构和已训练模型进行了打包，并放到了 `torchvision.model` 之中。我们可以直接对其进行加载。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验我们将使用 resenet18 网络结构来对蚂蚁和蜜蜂进行分类，该结构的网络模型如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"400px\" src=\"https://doc.shiyanlou.com/courses/2534/1166617/ec993cfb87cc866fd8823a61309ab6f5-0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以像上一章节一样，手动实现该模型，也可以直接加载预训练模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# 指定预训练模型的网络地址，如果不指定，则会从 PyTorch 官网上下载\n",
    "# 由于官网属于外网，速度很慢。因此这里已将模型上传至云服务器中\n",
    "torch.utils.model_zoo.load_url(\"https://labfile.oss.aliyuncs.com/courses/2534/resnet18-5c106cde.pth\")\n",
    "# 加载预训练模型\n",
    "# pretrained=False 表示只加载结构，不加载模型\n",
    "# pretrained=True：表示都加载\n",
    "model = models.resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么，是否上面这个模型就可以识别蜜蜂和蚂蚁了呢？或许细心的你已经发现，该模型的输出为 1000 个节点，而我们对蚂蚁和蜜蜂进行分类，只需要两个输出节点（节点的输出值为图像属于某类别的概率值）。综上，我们需要对 fc 层进行修改，使其只输出 2 个神经元节点。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# 获得 fc 层的输入节点数\n",
    "num_ftrs = model.fc.in_features\n",
    "# 重新定义 fc：输入节点数不变的情况下，将输出节点改为 2\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型的训练与测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 损失和优化器的定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们还是采用常用的交叉熵损失作为模型训练所需的损失函数，使用 SGD 优化器来对模型进行优化求解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在定义完优化器后，我们还可以定义一个学习率的变化器。传统梯度下降算法的学习率是不变的，我们可以利用 lr_scheduler 定义一个随着 epoch 变化的学习率。这样可以更好的优化模型，提高模型的准确率和收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "step_lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练与测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型训练之前，让我们先来定义两个变量 `best_model_wts` 和 `best_acc` ，用于存储最佳模型参数和最高的模型准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# deepcopy：深拷贝，就是保存模型的参数复制到另一个变量中\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_acc = 0.0\n",
    "best_model_wts, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在后面的模型训练中，我们会不断更新这两个变量，使这两个变量在训练过程中，一直保存着的最佳模型的参数和测试准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验，我们将训练过程和测试过程放在了一个循环之中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一次的迭代中，我们都先对所有数据进行梯度下降算法，优化模型参数。然后再利用测试集得到优化后的模型准确率。如果该准确率比 `best_acc` 大，则将该模型的参数复制给 `best_model_wts` ，再进行下一次的迭代。反之，则不保存，直接进行下一次的迭代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体代码如下所示（下面训练代码可能会运行 6~8 min，请耐心等待）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# 记录模型训练的开始时间\n",
    "since = time.time()\n",
    "# 开始训练,这里我们只设置迭代 5次\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # 每次迭代，都会对模型进行一次训练和一次测试\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # 告诉模型，现在是对模型进行训练，即需要梯度下降\n",
    "        else:\n",
    "            model.eval()   # 告诉模型，现在是对模型进行测试，即不需要梯度下降\n",
    "\n",
    "        # 定义每次跌打时的损失和准确率\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # 遍历数据生成器，训练时 phase = train，测试时 phase = val\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            # 如果 phase == 'train'，则打开梯度。否则，关闭梯度\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                # 获得预测结果和损失\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # 如果是模型训练，则需要反向传播\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # 统计损失值和正确的数据条数\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        # 更新学习率\n",
    "        if phase == 'train':\n",
    "            step_lr_scheduler.step()\n",
    "\n",
    "        # 计算当前损失和准确率\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "            phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # 如果此时的测试准确率比 best_acc，那么就将此时的模型存入 best_model_wts 中\n",
    "        # 将准确率存入 best_acc 中\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "# 模型训练完毕，计算花费时间\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# 加载训练过程中准确率最高的模型，作为输出的最后的模型\n",
    "model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们只对上面模型进行了 5 次训练，就得到了 90% 以上的测试准确率。从结果可以看出，通过迁移学习设置模型的初始化参数，可以在很短的时间内得到准确率较高的蜂蚁分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型的应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们利用建立的模型对任意一张图片进行识别。这里我从网上随机下载了一张蚂蚁的图片，让我们来验证一下，模型是否能够成功识别该图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先将图片下载到环境中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://labfile.oss.aliyuncs.com/courses/2534/ant.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们利用 PIL 加载该图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# 可以通过修改下面路径，对需要预测的图片进行修改\n",
    "infer_path = 'ant.jpg'\n",
    "img = Image.open(infer_path)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上图可以看到，该图像中存在很多的蚂蚁。在将图像放入模型中进行预测之前，我们需要对图片进行预处理，将图片处理成模型要求的输入格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file):\n",
    "    im = Image.open(file)\n",
    "    # 将大小修改为 224*224 符合模型输入\n",
    "    im = im.resize((224, 224), Image.ANTIALIAS)\n",
    "    # 建立图片矩阵\n",
    "    im = np.array(im).astype(np.float32)\n",
    "    # WHC->CHW\n",
    "    im = im.transpose((2, 0, 1))\n",
    "    im = im / 255.0\n",
    "    # 转为 batch,c,w,h\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "\n",
    "    print(\"im_shape 的维度\", im.shape)\n",
    "    return im\n",
    "\n",
    "\n",
    "# 测试函数\n",
    "img = load_image(infer_path)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后让我们将读出的影像放入模型之中，进行预测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = torch.tensor(img)\n",
    "outputs = model(img_data)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "print(\"The picture is \",class_names[preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果可以看出，我们的模型成功预测出了网上随机找的一张影像的类别。你也可以在找几张蚂蚁和蜜蜂的图像进行测试，我想具有 90% 的识别准确率的模型一般能够识别大多数的蚂蚁和蜜蜂图像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "综上，我们通过迁移学习，在很短时间内，训练出了具有良好的泛化能力和鲁棒性的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本实验首先讲解了迁移学习的相关概念，然后利用 PyTorch 加载了 resenet18 的预训练模型，对模型的最后一层进行了修改，得到蜂蚁分类模型的初始模型。最后，我们只需要对模型进行短时间的训练，就可以得到准确率较高的蜂蚁分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr><div style=\"color: #999; font-size: 12px;\"><i class=\"fa fa-copyright\" aria-hidden=\"true\"> 本课程内容版权归实验楼所有，禁止转载、下载及非法传播。</i></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
